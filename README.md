# LLMChatBotwithCybersecurity
A LLM chatbot for CSE120 Software Engineering Blue Diamond Growers Predictive Maintenance for Steel Dryer Bucket Pins with Cybersecurity Measures added

## Libraries
**Prompt Injection and Jail Break**
Developing libraries for prompt injection and jail break prompts to use for pentesting script to automate pentesting.

## Pentesting Scripts
Jupyter Notebook
Simple Python Script (takes in input from the prompt injection and jail break libraries text files and tests it)


## Planned Measures Added to Address Prompt Injection and Jail Break
Prompt sanitization.

## Planned Measures
Prevent SQL Injection
Gather a file on LLM Jailbreaks (Prompt Injection prompts and make a text file)

## Cybersecurity Terms 
Personally Identifiable Information (PII) is any data that can be used to specifically identify an individual with two categories: indirect and direct.

Examples of direct identifies include:
Social Security Numbers, Passport Numbers, and Driver's License Numbers



## References
1. https://github.com/R3DLB/LLM-Pentesting-Resources/tree/main
2. https://arxiv.org/html/2406.14549v1
3. https://www.crowdstrike.com/en-us/cybersecurity-101/identity-protection/personally-identifiable-information-pii/
4. https://neuraltrust.ai/blog/code-injection-in-llms


